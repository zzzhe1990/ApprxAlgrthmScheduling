roundVec: size of powK, includes the rounded time of each interval of powK.
Ntemp: size of powK. Includes the number of rounded long jobs fall into each time interval.
Cwhole: Includes all sub-configurations of Ntemp.
Ctemp: Machine Configurations. Includes all eligible sub-configurations of Ntemp that total run time of each sub-configuration is no larger than makespan T.
NStemp: size usually 1 smaller than Ctemp size because Ctemp includes the sub-configuration of all 0. Includes the remaining configurations of Ntemp-Ctemp.
AllTableElement: size is the # of all possible sub-configurations, size is same as Cwhole's. This is the dynamic programming table.
NSTableElement: This is basically the same as NStemp.
SumVec: This includes the total # of jobs for each single sub-configuration. After sorting this container, we are able to find configurations that have the same total # jobs, which are in same level.
counterVec: This includes the # of configurations that have the same total # of jobs. Size is the same as the # of levels. Indicates number of configurations in each level.

****************************************
Nov 27 2016
****************************************
Complete:
1. Initialize the device's array size of NSsubsets and optVector.
2. Initialize some device variables: dev_AllTableElemets_size, powK, 
3. Fix the problem of using incorrect sizes. In gpu_generate2(), the second parameter should be pow(k,2) instead of dev_ATE_elm_size.
4. Fix the problem of memory copy to device. Move memcpy() out of while() loop, which is in DPFunction2().
5. Add memcpy() from device to host for arrays: dev_counterVec, dev_ATE_NSsubsets, dev_ATE_optVector, dev_ATE_Csubsets. Copy these device arrays into "AllTableElemets" object.

Problem:
1. What is the real size of Csubsets()? Have to check the iteration of generate2() and CWhole.size() to see if the data size in 
	cudaMemcpy(AllTableElemets[i].Csubsets, &dev_ATE_Csubsets, DeviceToHost) is correct.



****************************************
Nov 28 2016
****************************************
Fixed Problem:
1. Nov 27 2016, Problem 1: Csubsets has a size of [Cwhole.size()][pow(k,2)]

Complete:
1. declaration of GPU functions.
2. first draft of initialization for all GPU functions.
3. update comments to make array sizes more explicit.

To do:
1. Compile code and debug.



****************************************
Dec 1 2016
****************************************
Complete:
1. Create header files for .cpp, so that .cu can include the header file to identify vector.
2. Move all cudaMalloc and cudaMemcpy to .cu file.
3. Move the While loop from DPFunction2 (in .cpp originally) to .cu.
4. Fix bugs on parameters.

Add:
1. makefile

Problem:
1. bugs about ifstream.
2. makefile problem.


****************************************
Dec 5 2016
****************************************
Complete:
1. solve the error of multiple definition
2. add memory copy from host to device for "counterVec"
3. correct the calculation on block size "bSize"
4. Make the code compiled correctly


****************************************
Dec 7 2016
****************************************
Complete:
1. Change the size of "optVec" and "NSsubsets" from fix value to dynamic. Size for mallocation is still fixed, but an array of size for different dimensionns are also recorded.
2. Add cudafree() for optVec_size and NSsubsets_size.
3. Change the size of cudaMemcpy for dev_counterVec from device to host. 


****************************************
Dec 12 2016
****************************************
Complete:
1. Address the problem of incorrect cudaMemcpy, caused by multi-dimensional vector. Copy from CUDA container to STL container directly may cause problems especially when 
   STL container is in multi-dimensions and not allocated.
2. Add cudaMemcpy Device to Host for myOPT and myOptimalindex. 
3. Change the way of copying between host and device; however, there is still heavy overhead on moving data from device (CUDA array) to host (STL vectors).

To do:
1. Run the original code on GRID to collect data and compare to GPU results.
2. Try to put all DPFunction2 on GPU to minimize the cost of communication.

Errors:
1. It shows that AllTableElemets[i].myOPT is always 1, which is not correct.

for(int i=0; i<NSTableElements.size();i++)			//NSTableElements is N - S. For example. (2,3), si = (0,1), then NS[i] = (2,2)
	{
		for(int j=0;j<AllTableElemets.size();j++)
		{	
			if(NSTableElements[i].elm==AllTableElemets[j].elm)
			{
				NSTableElements[i]=AllTableElemets[j];
				break;
			}
		}

	}


	for(int i=0; i<NSTableElements.size();i++)
	{
		tempOptVector.push_back(NSTableElements[i].myOPT);
	}

	int dpoptimal;
	int minN=100000;
    cout << "NSTableElements size: " << NSTableElements.size() << endl;  
	for(int mindex=0; mindex<NSTableElements.size();mindex++)
	{
		cout << "index: " << mindex << ", NSTableElements.myOPT: " << NSTableElements[mindex].myOPT << ", minN: " << minN << endl;
		if(NSTableElements[mindex].myOPT<minN)
			minN=NSTableElements[mindex].myOPT;
	}

	dpoptimal=minN +1;

*********************************************
Dec 17 2016
*********************************************
Problem solved:
1. Have to copy AllTableElemets[i].myOPT to GPU because it is not initialized to 0 but the number of total jobs.

Problem detected and still remain:
1. The update of optVector always hits the condition of NSsubsets == zeroVec. Problem might be caused by the updates on NSsubsets that some reserved elements (initial to 0) 
	are not updated (should not be used) but they are somehow used or compared to in GPU code. In cpp code, since it is a vector, there is no redudent elements, but in GPU code,
	size of arrays are reserved to MAX.
	
			if(gpu_sameVectors(&dev_ATE_NSsubsets[(j * Cwhole_size + h) * powK], dev_zeroVec, powK))
                {
                    //AllTableElemets[j].optVector.push_back(0);
                    dev_ATE_optVector[j * powK + optVecIndex] = 0;
                    optVecIndex++;
                    dev_ATE_optVector_size[j] = optVecIndex;
                    hit1++;
                    break;
                }
Solved!                
                
*********************************************
Dec 20
*********************************************
New found:
1. AllTableElemets[j].NSsubsets.size() is not constant, it is not the same to  AllTableElemets.size(). Find AllTableElemets[max].elm, for example: it is 0 0 5 2 3 0 6 0 0. Thus max NSsubsets.size()
   is 6 + 6*3 + 6*3*2 + 6*3*2*5. This value can be calculated between generate() and generate2().
2. AllTableElemets[j].NSsubsets[xxx].size() is constant to pow(k,2).
3. AllTableElemets[j].elm.size() is constant to pow(k,2).
4. The size of the first dimension of Csubsets is always equal to the max size of the first dimension of NSsubsets.

Completed:
1. Change NSsubsets_size to NSsubsets_size[max][pow(k,2)], where max is refered above.
2. Change the update for NSsubsets_size in gpu_generate2(). Now NSsubsets_size[] stores the value (??) of the first dimension of dev_NSsubsets[??][pow(k,2)].
3. The size of NSsubsets_size[] and dev_NSsubsets[] are calculated by using maxSubsetsSize instead of Cwhole_size.
4. The size of dev_NSsubsets is calculated by using maxSubsetsSize instead of Cwhole_size.

To do:
1. Add ostream to .cpp file and compare myOPT in .cpp to what is in .cu

**********************************************
Dec 21
**********************************************
1. GPU returns same minn as .cpp's from DPFunction2; however, NSTableElements[i].myOPT is constant to 6 when it is on GPU which is either 6 or 7 in .cpp's run.

Changed but caused other problem:
1. when doing cudaMemcpy from Device to Host, changes are made to dev_NSsubsets because the vector "NSsubsets" only requires the elements within the scope of dev_NSsubsets_Size. 
2. Execution errors that cudaMalloc is out of memory. Or it complains about the cudaMemcpyDeviceToHost for counterVec.
3. cudaMemcpyDeviceToHost for counterVec can be removed by placing dev_counterVec on device permenantly and updated on device.

Undo the changes by restoring the previous commit.


**********************************************
Dec 28
**********************************************
New found:
1. Don't need to memcpy dev_counterVec back to counterVec because it is not changed on GPU.
	This memcpy is removed.

Problem resolved:
1. Sometimes cuda API complains about the out of bounds error on memcpy(temp_NSsubsets, dev_NSsubsets, size, DeviceToHost), even if the size of dev_NSsubsets is only around 0.5 GB.
   Resolved:  AllTableElemets[maxIndex].elm.end() returns invalid big number, it is known that using vector<int>::const_iterator pt sometimes return invalid value which implies that iterator pt
   sometimes access memory location which is out of bound. Work around: Instead of using vector<int>::const iterator, using index.
   
Problem detected:
2. Problem of myOPT still exists and impact the GPU results. On GPU, NSTableElemets.myOPT is different from CPU implementation.
Not solved.
3. Sometimes "unspecified launch failure", error returned by API calls like memcpy and cudaDeviceSynchronize. The first error returned by memcpy(NSsubset, DeviceToHost)
    Resolved!
***********************************************
Dec 29
************************************************
Problem resolved:
1. myMinNSVector is not copied back to CPU from Device.
	Resolved: copy it back to cpu.
	
2. IN the if statement "if (NSTableElemets.elm == AllTableElemets.elm)", the AllTableElemets that identical to the NSTableElemets.elm on GPU are at different indexes comparing to on CPU's.
	Resolved: Running on different machines would result in different elm. When ruuning on lab's machine, CPU has the same index as got from GPU. Reason is still unknown.

Problem detected:
1. At the last iteration, which is the iteration that LB == UB, GPU implementation failed to call CUDA API. "Unknown specified launch failure" on memcpy device to host.
	Resolved!!

*************************************************
Dec 30
**************************************************
Problem resolved:
1. At the last iteration, which is the iteration that LB == UB, GPU implementation failed to call CUDA API. "Unknown specified launch failure" on memcpy device to host.
	Solution: dev_ATE_optVector was initialized to AllTableElemets.size() * powK, which is not correct and should be AllTableElemets.size() * (maxSumValue + 1).

Problem detected:
1. Debug mode completes successfully even if it returns incorrect result, but release mode still crashes.
	The divergence in gpu_increase() causes the error of "hardware stack overflow"
    Resolved!!!
	
*************************************************
Dec 31
*************************************************
Problem resolved:
1. Debug mode completes successfully even if it returns incorrect result, but release mode still crashes.
	The divergence in gpu_increase() causes the error of "hardware stack overflow"	
	Solution: the first parameter of gpu_increase() is a pointer, but it was declared as "const int*" which causes the "warp hardware stack overflow" error.
	
*************************************************
Jan 16
*************************************************
Problem remain:
1. myOPT does not match
	Cause detected: somme AllTableElemets[j].myOPT on GPU do not match CPU's
2. CPU crashes

**************************************************
Jan 22
***************************************************
Problem Resolved:
1. myOPT does not match
	AllTableElemets[j].optVector was initialized to maxSumValue, which is not appropraite. Now it is hard-code to 64. Also, to access this array, the gap should be 64 instead of powK.
	
*************************************************
Jan 31
*************************************************
Problem detected:
1. CPU crashes when doing memory copy from vectors to "instance", which is created to store the latest feasible solution. Since the size of vector is unknown, all data including none-useful data are 
	copying back to the vectors from GPU. Therefore, the vectors' sizes are too large and takes so long time to do memory copy on CPU.
	
	Reason: For GPU implementation, arrays on GPU takes so much memory because it does not support vector, and these arrays are copied to CPU and store in vectors which still contain huge extra 
			memory that are not taken in MPI code. 

**************************************************
March 5
**************************************************
Complete:
1. Split Upper bound and Low bound by 4 instead of binary cut.
2. Launch Multithreading and apply each cut segment to one stream.

Optimization:
1. Now we have multithreading supported and each thread handles one segment.
2. Each thread executes both memory copy and kernels in its own local stream.
3. Multiple threads thus are ran in different streams so that work context of each segment can be executed concurrently.
4. Reduce the size of "maxSubsetsSize" to a much smaller value like 256 or 512. 
		
Problem: 
For the change on "maxSubsetsSize". Occationally, memcpy returns error, complaining about the size. Cause is unknown yet.

Parallelism:
Each FindOPT kernel represents a level. And each thread in the kernel represents a sub-configuration.

To do:
1. Modify Dynamic Programming algorithm to improve the efficiency of each kernel 
2. For each segment on a thread, there are multiple kernels which might be independent but now running in serial because they are in the same stream. Try to run these kernels in multiple streams.


**************************************************
March 29
**************************************************
Bug fixed:
In MainScheduling, the operation for selecting the correct segment for next iteration has a bug that the 3rd statement should be "if (i < seg-1)" to include the right most segment.

Potential Work:
1. Split multi-dimension table into sub-blocks.
2. For a configuration N, current implementation compares all its NSsubsets to AllTableElemets to find info for all feasible sub-configuration (code shown below); 
	it might not be necessary. Greedy here might helpful on reducing operations, which is to find the configuration that takes maximum time. Also, using the idea of splitting multi-dimension table
	into sub-blocks can result in the benefit of reducing the iteration on "r" because we have locate the block that configuration resides and iterate that block only.
				for (int r = 0; r < AllTableElemets_size; r++)
                {					
                    //if(AllTableElemets[j].NSsubsets[h]==AllTableElemets[r].elm)   // if found match of NSsubsets[h], copy its OPT and break 

                   
                    if (gpu_sameVectors(&dev_ATE_NSsubsets[(j * maxSubsetsSize + h) * powK], &dev_ATE_elm[r * powK], powK))
                    {
                        //AllTableElemets[j].optVector.push_back(AllTableElemets[r].myOPT);
                        dev_ATE_optVector[j * optVectorSize + optVecIndex] = dev_ATE_myOPT[r];                       						
                        optVecIndex++;
						dev_ATE_optVector_size[j] = optVecIndex;
											
                        break;
                    }
                }


*************************************************
April 8
*************************************************
Implemented:
1. parallel implementation for finding if two vectors are same in implemented, but worse performance.
2. parallel implementation for generate2 is done, no good performance due to te in-consuctive acceptance on subconfigurations.


**************************************************
June 19
**************************************************
Bug fixed:
1. dev_ATE_optVector and dev_ATE_optVector_size were used directly but it should be applied with an offset
	changes made: 
	In function LaunchBlock, 	int *bOptVec_size = &dev_ATE_optVector_size[configOffset];
								int *bOptVec = &dev_ATE_optVector[configOffset * optVectorSize];
								
**************************************************
Aug 1
**************************************************
Bug fixed:
1. In DPCUDA.cu, the part that calculating "blockOffset" (just above function "LaunchBlocks<<<>>>()" was wrong because "allBlocksNoZero" was initialized incorrectly.
				//blockOffset returns the current block ID.
				int blockOffset = gpu_blockOffsetNoZero(&allBlocksNoZero[b].elm[0], &divisor[0], allBlocksNoZero[b].elm.size(), divisor.size());
	Solution: update allBlocksNoZero to make it correct.
	
Resolution:
	Program now returns correct result.
				
***************************************************
Aug2
***************************************************
In Parallel.cpp function "mainScheduling", the part for deciding which segment should be picked.
	if (dirc[0] == -1)... else if (dirc[seg-1] == 1)... else { for (int i=1; i<seg; i++)}
	
	for an example of segs: 1, -1, -1. If it is the last segments that each segment has only one element, we should probably pick the "1" segment. However, if the segments are that each has 
	multiple elements, we should pick the first "-1" segment.
	

***************************************************
Aug 22
***************************************************
Problem detected:
1. Incorrect results for File3-1.
2. Memory issue. DPCUDA.cu:864 memcpyAsync


****************************************************
Sep 5
****************************************************
Optimization:
1. In FindOPT kernel function, there is a for loop "for(int h=0; h < dev_ATE_NSsubsets_size[j]; h++)" can be replaced by a kernel function.

Problem resolved:
1. Segment fault. Caused by "MulAllProbData" that the accepted OPT result of 4 threads will be stored into MulAllProbData and then select the best from 4; however, if a thread has OPT greater than 
   the threshold, it does not store any data which means MulAllProbData[thread] will not be initialized. Thus, the access to this address would cause memory issue.
2. In the kernel function which is developed to unroll the for loop, which is for looping through all sub-configurations and update their OPT, __shared__ lock[1] is only shared by the thread within 
   the same block, so that the block size should be big enough to include all possible optVector. Otherwise, it would generate multiple block, and lock[1] will only be effective to each block itself.
   Also, __threadfence() is necessary to ensure the shared and global memory writes.
   
****************************************************
Sep 10
****************************************************
Problem resolved:
1. In "MlDPFunction2()", the previous calculation for "divisor" could get a result of all 1 because it's possible that the configuration size of all dimensions could be prime numbers. 
   In this case, there is no split and all jobs are executed in one big block. Thus, update the max N dimensions' divisor to the same size as its dimension weight to ensure the multile blocks.
   
To do:
1. Change the way of 4-way splitting. Previously, 4 splits are evenly placed between UB and LB; however, this is not efficient because most data resides in some specific area (dense). 
   Also, there are more long jobs if the cut is more close to LB. Because with a smaller T (T = (UB+LB)/2 ), there are more jobs greater than T considered as long jobs.
2. Change the "do....while()" loop in "gpu_generate2" kernel function into for loops, and unroll the for loop with a kernel function.

****************************************************
Sep 11
****************************************************
Problem detected:
1. Csubsets is not necessary if host function "finalScheduleFun2" is not called.
2. NS array might be replaced by kernel local array.
3. With the improvement to global function "gpu_generate2", the results for File1-4 and 1-15 are not correct.

Performance VS:
1. For File2-16, GPU is much faster, and this file is computation intense.
2. For File3-16, 3-17, 3-18, GPU is much faster.

******************************************************
Sep 15
******************************************************
Problem resolved:
1. In function "FindOPT", instead of returning back to lock (FindOPT kernel thread) after lauching the "loopNS" kernel function, merging the sort operation into "loopNS" also to ensure 
   the coherence of memory update.
  
TO DO:
1. Some global arrays, like dev_optVector, dev_optVector_size, dev_Csubsets can be removed or replaced by shared memory. Even dev_NSsubsets can be removed, 
   if function "FindOPT" is merged to "gpu_generate2".																			(optVector, optVector_size, Csubsets are removed)
2. The use of multiple streams for each block may not be necessary.
