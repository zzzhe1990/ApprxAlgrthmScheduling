****************************************
Nov 27 2016
****************************************
Complete:
1. Initialize the device's array size of NSsubsets and optVector.
2. Initialize some device variables: dev_AllTableElemets_size, powK, 
3. Fix the problem of using incorrect sizes. In gpu_generate2(), the second parameter should be pow(k,2) instead of dev_ATE_elm_size.
4. Fix the problem of memory copy to device. Move memcpy() out of while() loop, which is in DPFunction2().
5. Add memcpy() from device to host for arrays: dev_counterVec, dev_ATE_NSsubsets, dev_ATE_optVector, dev_ATE_Csubsets. Copy these device arrays into "AllTableElemets" object.

Problem:
1. What is the real size of Csubsets()? Have to check the iteration of generate2() and CWhole.size() to see if the data size in 
	cudaMemcpy(AllTableElemets[i].Csubsets, &dev_ATE_Csubsets, DeviceToHost) is correct.



****************************************
Nov 28 2016
****************************************
Fixed Problem:
1. Nov 27 2016, Problem 1: Csubsets has a size of [Cwhole.size()][pow(k,2)]

Complete:
1. declaration of GPU functions.
2. first draft of initialization for all GPU functions.
3. update comments to make array sizes more explicit.

To do:
1. Compile code and debug.



****************************************
Dec 1 2016
****************************************
Complete:
1. Create header files for .cpp, so that .cu can include the header file to identify vector.
2. Move all cudaMalloc and cudaMemcpy to .cu file.
3. Move the While loop from DPFunction2 (in .cpp originally) to .cu.
4. Fix bugs on parameters.

Add:
1. makefile

Problem:
1. bugs about ifstream.
2. makefile problem.


****************************************
Dec 5 2016
****************************************
Complete:
1. solve the error of multiple definition
2. add memory copy from host to device for "counterVec"
3. correct the calculation on block size "bSize"
4. Make the code compiled correctly


****************************************
Dec 7 2016
****************************************
Complete:
1. Change the size of "optVec" and "NSsubsets" from fix value to dynamic. Size for mallocation is still fixed, but an array of size for different dimensionns are also recorded.
2. Add cudafree() for optVec_size and NSsubsets_size.
3. Change the size of cudaMemcpy for dev_counterVec from device to host. 


****************************************
Dec 12 2016
****************************************
Complete:
1. Address the problem of incorrect cudaMemcpy, caused by multi-dimensional vector. Copy from CUDA container to STL container directly may cause problems especially when 
   STL container is in multi-dimensions and not allocated.
2. Add cudaMemcpy Device to Host for myOPT and myOptimalindex. 
3. Change the way of copying between host and device; however, there is still heavy overhead on moving data from device (CUDA array) to host (STL vectors).

To do:
1. Run the original code on GRID to collect data and compare to GPU results.
2. Try to put all DPFunction2 on GPU to minimize the cost of communication.

Errors:
1. It shows that AllTableElemets[i].myOPT is always 1, which is not correct.

for(int i=0; i<NSTableElements.size();i++)			//NSTableElements is N - S. For example. (2,3), si = (0,1), then NS[i] = (2,2)
	{
		for(int j=0;j<AllTableElemets.size();j++)
		{	
			if(NSTableElements[i].elm==AllTableElemets[j].elm)
			{
				NSTableElements[i]=AllTableElemets[j];
				break;
			}
		}

	}


	for(int i=0; i<NSTableElements.size();i++)
	{
		tempOptVector.push_back(NSTableElements[i].myOPT);
	}

	int dpoptimal;
	int minN=100000;
    cout << "NSTableElements size: " << NSTableElements.size() << endl;  
	for(int mindex=0; mindex<NSTableElements.size();mindex++)
	{
		cout << "index: " << mindex << ", NSTableElements.myOPT: " << NSTableElements[mindex].myOPT << ", minN: " << minN << endl;
		if(NSTableElements[mindex].myOPT<minN)
			minN=NSTableElements[mindex].myOPT;
	}

	dpoptimal=minN +1;

*********************************************
Dec 17 2016
*********************************************
Problem solved:
1. Have to copy AllTableElemets[i].myOPT to GPU because it is not initialized to 0 but the number of total jobs.

Problem detected and still remain:
1. The update of optVector always hits the condition of NSsubsets == zeroVec. Problem might be caused by the updates on NSsubsets that some reserved elements (initial to 0) 
	are not updated (should not be used) but they are somehow used or compared to in GPU code. In cpp code, since it is a vector, there is no redudent elements, but in GPU code,
	size of arrays are reserved to MAX.
	
			if(gpu_sameVectors(&dev_ATE_NSsubsets[(j * Cwhole_size + h) * powK], dev_zeroVec, powK))
                {
                    //AllTableElemets[j].optVector.push_back(0);
                    dev_ATE_optVector[j * powK + optVecIndex] = 0;
                    optVecIndex++;
                    dev_ATE_optVector_size[j] = optVecIndex;
                    hit1++;
                    break;
                }
Solved!                
                
*********************************************
Dec 20
*********************************************
New found:
1. AllTableElemets[j].NSsubsets.size() is not constant, it is not the same to  AllTableElemets.size(). Find AllTableElemets[max].elm, for example: it is 0 0 5 2 3 0 6 0 0. Thus max NSsubsets.size()
   is 6 + 6*3 + 6*3*2 + 6*3*2*5. This value can be calculated between generate() and generate2().
2. AllTableElemets[j].NSsubsets[xxx].size() is constant to pow(k,2).
3. AllTableElemets[j].elm.size() is constant to pow(k,2).
4. The size of the first dimension of Csubsets is always equal to the max size of the first dimension of NSsubsets.

Completed:
1. Change NSsubsets_size to NSsubsets_size[max][pow(k,2)], where max is refered above.
2. Change the update for NSsubsets_size in gpu_generate2(). Now NSsubsets_size[] stores the value (??) of the first dimension of dev_NSsubsets[??][pow(k,2)].
3. The size of NSsubsets_size[] and dev_NSsubsets[] are calculated by using maxSubsetsSize instead of Cwhole_size.
4. The size of dev_NSsubsets is calculated by using maxSubsetsSize instead of Cwhole_size.

To do:
1. Add ostream to .cpp file and compare myOPT in .cpp to what is in .cu

**********************************************
Dec 21
**********************************************
1. GPU returns same minn as .cpp's from DPFunction2; however, NSTableElements[i].myOPT is constant to 6 when it is on GPU which is either 6 or 7 in .cpp's run.

Changed but caused other problem:
1. when doing cudaMemcpy from Device to Host, changes are made to dev_NSsubsets because the vector "NSsubsets" only requires the elements within the scope of dev_NSsubsets_Size. 
2. Execution errors that cudaMalloc is out of memory. Or it complains about the cudaMemcpyDeviceToHost for counterVec.
3. cudaMemcpyDeviceToHost for counterVec can be removed by placing dev_counterVec on device permenantly and updated on device.

Undo the changes by restoring the previous commit.


**********************************************
Dec 28
**********************************************
New found:
1. Don't need to memcpy dev_counterVec back to counterVec because it is not changed on GPU.
	This memcpy is removed.

Problem resolved:
1. Sometimes cuda API complains about the out of bounds error on memcpy(temp_NSsubsets, dev_NSsubsets, size, DeviceToHost), even if the size of dev_NSsubsets is only around 0.5 GB.
   Resolved:  AllTableElemets[maxIndex].elm.end() returns invalid big number, it is known that using vector<int>::const_iterator pt sometimes return invalid value which implies that iterator pt
   sometimes access memory location which is out of bound. Work around: Instead of using vector<int>::const iterator, using index.
   
Problem detected:
2. Problem of myOPT still exists and impact the GPU results. On GPU, NSTableElemets.myOPT is different from CPU implementation.
Not solved.
3. Sometimes "unspecified launch failure", error returned by API calls like memcpy and cudaDeviceSynchronize. The first error returned by memcpy(NSsubset, DeviceToHost)
    Resolved!
***********************************************
Dec 29
************************************************
Problem resolved:
1. myMinNSVector is not copied back to CPU from Device.
	Resolved: copy it back to cpu.
	
2. IN the if statement "if (NSTableElemets.elm == AllTableElemets.elm)", the AllTableElemets that identical to the NSTableElemets.elm on GPU are at different indexes comparing to on CPU's.
	Resolved: Running on different machines would result in different elm. When ruuning on lab's machine, CPU has the same index as got from GPU. Reason is still unknown.

Problem detected:
1. At the last iteration, which is the iteration that LB == UB, GPU implementation failed to call CUDA API. "Unknown specified launch failure" on memcpy device to host.
	Resolved!!

*************************************************
Dec 30
**************************************************
Problem resolved:
1. At the last iteration, which is the iteration that LB == UB, GPU implementation failed to call CUDA API. "Unknown specified launch failure" on memcpy device to host.
	Solution: dev_ATE_optVector was initialized to AllTableElemets.size() * powK, which is not correct and should be AllTableElemets.size() * (maxSumValue + 1).

Problem detected:
1. Debug mode completes successfully even if it returns incorrect result, but release mode still crashes.
	The divergence in gpu_increase() causes the error of "hardware stack overflow"
    Resolved!!!
	
*************************************************
Dec 31
*************************************************
Problem resolved:
1. Debug mode completes successfully even if it returns incorrect result, but release mode still crashes.
	The divergence in gpu_increase() causes the error of "hardware stack overflow"	
	Solution: the first parameter of gpu_increase() is a pointer, but it was declared as "const int*" which causes the "warp hardware stack overflow" error.
	
*************************************************
Jan 16
*************************************************
Problem remain:
1. myOPT does not match
	Cause detected: somme AllTableElemets[j].myOPT on GPU do not match CPU's
2. CPU crashes

**************************************************
Jan 22
***************************************************
Problem Resolved:
1. myOPT does not match
	AllTableElemets[j].optVector was initialized to maxSumValue, which is not appropraite. Now it is hard-code to 64. Also, to access this array, the gap should be 64 instead of powK.
	
*************************************************
Jan 31
*************************************************
Problem detected:
1. CPU crashes when doing memory copy from vectors to "instance", which is created to store the latest feasible solution. Since the size of vector is unknown, all data including none-useful data are 
	copying back to the vectors from GPU. Therefore, the vectors' sizes are too large and takes so long time to do memory copy on CPU.
	
	Reason: For GPU implementation, arrays on GPU takes so much memory because it does not support vector, and these arrays are copied to CPU and store in vectors which still contain huge extra 
			memory that are not taken in MPI code. 
